{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEMS THE PAPER ADDRESSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a deep network with high accuracy while keeping computation low. Google being a company wanted something that can be used practically in the real world and not be shelved as an academic wonder for decades. Winning ImageNet competition is just and added extra bonus!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incepetion Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing a layer for a ConvNet, you might have to pick, do you want a 1 by 3 filter, or 3 by 3, or 5 by 5, or do you want a pooling layer? The best path is to somehow choose the best layer combination for the whole network! But there is no method to do this! Or is there?What the inception network does is it says, why should you do them all? And this makes the network architecture more complicated, but it also works remarkably well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory you can have as many filter sizes as possible, but the Inception Architecture is restricted to filter sizes 1 × 1, 3 × 3 and 5 × 5. The small filters help capture the local details and features whereas spread out features of higher abstraction are captured by the larger filters. A 3 × 3 max pooling is also added to the Inception architecture, because, why not? Historically, it has been found that pooling layers make the network work better, so might as well add them!\n",
    "\n",
    "\n",
    "\n",
    "the basic idea is that instead of you needing to pick one of these filter sizes or pooling you want and committing to that, you can do them all and just concatenate all the outputs, and let the network learn whatever parameters it wants to use, whatever the combinations of these filter sizes it wants. Now it turns out that there is a problem with the inception layer  which is computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One big problem with the above naive form of the inception module is that the large convolution are computationally expensive.\n",
    "\n",
    "Let’s just examine what the 5×5 convolution would be computationally:\n",
    "![5x5-convolution](5x5-convolution.png)\n",
    "\n",
    "In the above convolution, there would be,\n",
    "\n",
    " \n",
    "\n",
    "(5²)(192)(32)(28²) = 120,422,400 operations\n",
    "\n",
    "This is a lot of computation!\n",
    "\n",
    "Something must be done to bring down this number! A method to reduce the number of computation is Dimensionality Reduction. This involves convolutions with 1 × 1 filters before convolutions with bigger filters.\n",
    "\n",
    "Let’s look at the 5 × 5 convolution with dimensionality reduction:\n",
    "![5x5-dimensionality](5x5-dimensionality.png)\n",
    "\n",
    "\n",
    "In the above there would be,\n",
    "\n",
    "(1²)(192)(16)(28²) = 2,408,448 operations for the 1 × 1 convolution and,\n",
    "\n",
    "(5²)(16)(32)(28²) = 10,035,200 operations for the 5 × 5 convolution.\n",
    "\n",
    "In total there will be 2,408,448 + 10,035,200 = 12,443,648 operations. This is a reduction in the total amount of computation by about a factor of 10!\n",
    "\n",
    "Not only do these 1 × 1 convolutions help reduce the dimensions but also had the extra benefit of adding an extra non-linearity, thus, making the model map even more complex functions.\n",
    "\n",
    "Similar is the case with the 3 × 3 layer. Also, pooling layers preserve the depth. As a result, the depth keeps on increasing rapidly. To prevent this a 1 × 1 conv. layer is added after the 3 × 3 max pooling layer in the inception module, with a lower number of filters to reduce the depth of the output feature map.\n",
    "\n",
    "\n",
    "One thing to note is that the output spatial dimension of an Inception Module matches that of the input to it i.e. only the depth gets effected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![inception module](inception_module.JPG)\n",
    "\n",
    "\n",
    "So this is one inception module, and what the inception network does, is, more or less, put a lot of these modules together.\n",
    "\n",
    "\n",
    "\n",
    "![googlenet_architecture](googlenet_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is 22 layers deep. The initial layers are simple convolution layers. After that there are multiple blocks of inception modules with layers of max pooling following some of the blocks. The spatial dimensions get affected by these max pooling layers only. Another interesting addition to the architecture is to change the second last fully-connected layer with an average pooling layer. This layer spatially averages the feature map, converting 7 × 7 × 1024 input to 1 × 1 × 1024. Doing not only reduces the computation and the number of parameters, by a factor of 49, of the network but also improves the accuracy of the model, improving top-1 accuracy by 0.6%. This average pooling layer is finally followed by a normal fully-connected layer with 1000 neurons (and 1024 × 1000 parameters), for the 1000 ImageNet classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main driving force for this work was to make sure conv. nets don’t remain academic wonders but are practically usable in the daily world. It did achieve this really well. The number of parameters, and hence size, is considerably less than many well performing networks like AlexNet and VGGNet but without any sacrifice in accuracy! Though, due to the complex architecture of GoogLeNet (Inception Module), many people tend to shy away from using it and pick the simple and uniform VGGNet for small tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://mohitjain.me/2018/06/09/googlenet/\n",
    "- https://www.youtube.com/watch?v=C86ZXvgpejM&t=2s\n",
    "- https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfx",
   "language": "python",
   "name": "tfx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
