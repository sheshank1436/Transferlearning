{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Stanford Cars using Keras Alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Content\n",
    "\n",
    "* [Data Exploratory](#exploratory)\n",
    "* [Data Selection](#selection)\n",
    "* [Data Split](#split)\n",
    "* [Implementation](#implementation)\n",
    "* [Analyze](#analyze)\n",
    "* [Prediction](#prediction)\n",
    "* [Reference](#reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The goal of this notebook is simply to show the implementation of the AlexNet and train a model to predict certain types of Cars\n",
    "\n",
    "## Definition\n",
    "\n",
    "AlexNet is the name of a convolutional neural network (CNN), designed by Alex Krizhevsky, and published with Ilya Sutskever and Krizhevsky's doctoral advisor Geoffrey Hinton.\n",
    "\n",
    "AlexNet competed in the ImageNet Large Scale Visual Recognition Challenge on September 30, 2012. The network achieved a top-5 error of 15.3%, more than 10.8 percentage points lower than that of the runner up. The original paper's primary result was that the depth of the model was essential for its high performance, which was computationally expensive, but made feasible due to the utilization of graphics processing units (GPUs) during training.\n",
    "\n",
    "https://en.wikipedia.org/wiki/AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exploratory'></a>\n",
    "# Data Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPool2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv('../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/names.csv')\n",
    "names = names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='selection'></a>\n",
    "# Data Selection\n",
    "\n",
    "Select only a limited amount of cars to train on just because Kaggle does not support to train on all data at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_cars = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_name = {x : names[x][0] for x in np.arange(nr_cars)}\n",
    "name_to_idx = {x:i for i,x in enumerate(idx_to_name.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bentley Continental GT Coupe 2012',\n",
       " 1: 'Audi S4 Sedan 2012',\n",
       " 2: 'Hyundai Santa Fe SUV 2012',\n",
       " 3: 'Spyker C8 Coupe 2009',\n",
       " 4: 'GMC Acadia SUV 2012',\n",
       " 5: 'BMW Z4 Convertible 2012',\n",
       " 6: 'BMW 6 Series Convertible 2007',\n",
       " 7: 'Bentley Arnage Sedan 2009',\n",
       " 8: 'FIAT 500 Abarth 2012',\n",
       " 9: 'Acura Integra Type R 2001'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/car_data/train/'\n",
    "test_path = '../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/car_data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    train = []\n",
    "    for i, name in enumerate(name_to_idx.keys()):\n",
    "        new_path = path + name + \"/\"\n",
    "        [train.append([i, cv2.resize(cv2.imread(img), (244,244), interpolation = cv2.INTER_AREA)]) for img in glob.glob(new_path + \"*.jpg\")]\n",
    "    return np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_data(train_path)\n",
    "test = get_data(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='split'></a>\n",
    "# Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate(train[:,1], axis=0).reshape(len(train), 244, 244, 3)\n",
    "X_train = X_train / 255.0\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = train[:,0]\n",
    "y_train = np.eye(len(idx_to_name))[list(y_train)]\n",
    "\n",
    "X_test = np.concatenate(test[:,1], axis=0).reshape(len(test), 244, 244, 3)\n",
    "X_test = X_test / 255.0\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = test[:,0]\n",
    "y_test = np.eye(len(idx_to_name))[list(y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='implementation'></a>\n",
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=left src='https://dpzbhybb2pdcj.cloudfront.net/elgendy/v-8/Figures/05-06_img_0050.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Alexnet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 58,327,818\n",
      "Trainable params: 58,325,066\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an empty sequential model\n",
    "model = Sequential(name=\"Alexnet\")\n",
    "# 1st layer (conv + pool + batchnorm)\n",
    "model.add(Conv2D(filters= 96, kernel_size= (11,11), strides=(4,4), padding='valid', kernel_regularizer=l2(0.0005),\n",
    "input_shape = (227,227,3)))\n",
    "model.add(Activation('relu'))  #<---- activation function can be added on its own layer or within the Conv2D function\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides= (2,2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "# 2nd layer (conv + pool + batchnorm)\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same', kernel_regularizer=l2(0.0005)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "            \n",
    "# layer 3 (conv + batchnorm)      <--- note that the authors did not add a POOL layer here\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=l2(0.0005)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "        \n",
    "# layer 4 (conv + batchnorm)      <--- similar to layer 3\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=l2(0.0005)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "            \n",
    "# layer 5 (conv + batchnorm)  \n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=l2(0.0005)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Flatten the CNN output to feed it with fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# layer 6 (Dense layer + dropout)  \n",
    "model.add(Dense(units = 4096, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# layer 7 (Dense layers) \n",
    "model.add(Dense(units = 4096, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "                           \n",
    "# layer 8 (softmax output layer) \n",
    "model.add(Dense(units = len(y_train[0]), activation = 'softmax'))\n",
    "\n",
    "# print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce learning rate by 0.1 when the validation error plateaus\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1))\n",
    " \n",
    "# set the SGD optimizer with lr of 0.01 and momentum of 0.9\n",
    "optimizer = SGD(lr = 0.01, momentum = 0.9)\n",
    " \n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "# call the reduce_lr value using callbacks in the training method\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test),\n",
    "    verbose=0, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analyze'></a>\n",
    "# Analyze training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction'></a>\n",
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    to_predict = np.zeros(shape=X_train.shape)\n",
    "    to_predict[0] = img\n",
    "    \n",
    "    return idx_to_name[np.argmax(model(to_predict)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(X_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reference'></a>\n",
    "# Reference\n",
    "\n",
    "AlexNet kaggle layers design and architecture image:<br>\n",
    "https://www.manning.com/books/deep-learning-for-vision-systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
